<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.77f0b837e2fd40b3baf5.css" data-identity="gatsby-global-css">@import url(https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400;0,700;1,400&family=IBM+Plex+Mono&family=Lora:wght@400;600&family=Nunito&family=Public+Sans:wght@300&family=Source+Sans+Pro:wght@400;600;700&display=swap);body{background-color:rgba(181,189,203,.05);margin:50px auto 0;width:800px}*{border:0;margin:0;padding:0}li,p{color:#58614e;font-family:Helvetica Neue,Arial,sans-serif;font-size:11pt;font-style:normal}li p{padding-bottom:0!important}blockquote{border-left:3px solid #3fb399;margin:1em;padding:0 25px}blockquote p{font-family:EB Garamond!important;font-size:12pt!important;margin:10px;padding:0!important}.post-date{color:#584b77!important;display:inline-block;font-family:Courier New,Courier,monospace;font-size:12pt;font-weight:700;padding-bottom:10px;text-decoration:none}.post-time{color:rgba(0,0,0,.5);display:inline;font-family:Public Sans;font-size:11pt}.post-time:before{color:rgba(0,0,0,.5);content:" • ";padding:3px}.blog-post{padding:30px 60px 40px 40px;width:519px}.blog-post h1{font-family:EB Garamond;font-size:24pt}.blog-post h1,.blog-post h2{color:#584b77;font-style:normal;font-weight:500;padding-bottom:10px}.blog-post h2{font-family:Public Sans;font-size:12pt;padding-top:10px}.blog-post h5{font-family:EB Garamond;font-size:13pt;font-variant-caps:small-caps;font-weight:400}.blog-post h4,.blog-post h5{font-style:normal;line-height:17px;padding-bottom:10px}.blog-post h4{font-family:HelveticaNeue-Light,Helvetica Neue,Arial,sans-serif;font-size:10pt}.blog-post p{line-height:1.6;padding-bottom:1em;position:relative}.annotation{font-size:9pt;left:560px;line-height:1.15;position:absolute;width:150px}.preview p{line-height:1.15;padding-bottom:10px}.blog-post a{color:#008b66;text-decoration:none}.blog-post a.noHighlight{color:#58614e;text-decoration:none}.blog-post a.noHighlight:hover{color:#337261;text-decoration:underline}.blog-post img{display:block;margin-left:auto;margin-right:auto;padding:30px 0}.blog-post b{color:#7d3f1a}.blog-post ul{padding-bottom:10px}.blog-post li{line-height:1.6;margin-left:20px}</style><meta name="generator" content="Gatsby 3.13.0"/><link as="script" rel="preload" href="/webpack-runtime-6211f90e7b9220d56700.js"/><link as="script" rel="preload" href="/framework-c994c0529d0491ad085b.js"/><link as="script" rel="preload" href="/app-019f857f2e3d4b0b87b4.js"/><link as="script" rel="preload" href="/component---src-pages-markdown-remark-frontmatter-slug-js-8a69e30532d0b70ad663.js"/><link as="fetch" rel="preload" href="/page-data/perception/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="blog-post-container"><title>Perception and adversarial examples</title><div class="blog-post"><div class="blog-post-content"><h1>Perception and adversarial images</h1>
<p>In the human brain, no less than 1/5th of the visual cortex is dedicated to facial recognition. So long as it has improved survival, we've become more and more sensitive to the curves of the human face.</p>
<p>Compare that to how the face of, say, an elephant appears to us, and you and I can simulate how largely our perceptions are distortions of the objective world. In our world, human faces are fundamentally higher-resolution than anything else.</p>
<blockquote>
<p><strong>The interface theory of perception</strong>: the perceptions of an organism are a user interface between that organism and the objective world</p>
</blockquote>
<p>Our perceptions care a little bit about the statistical structure of the universe, but mostly care about our survival. So if you add some noise to a scene which then renders it a physical impossibility, we don't actually care. We don't see it.</p>
<p>An ML model is trained under different conditions.</p>
<p>Could it be that an adversarial image — a picture with added noise, or a single black pixel — is actually a physical impossibility, a perversion of the way EM waves travel in the universe? Could it be that ML models actually learn the underlying statistics of images, and become confused when presented with what seems to them to be an obvious impossibility?</p>
<p>Rather than saying the ML failed because it didn't see the airplane after the noise was added, perhaps the questions is, how come <em>we</em> don't see all the blatant noise that has been added to the airplane?</p>
<p>Marley
11/4/2021, 4:38:00 PM</p>
<p><a href="https://stanislavfort.github.io/blog/OpenAI_CLIP_adversarial_examples/">Adversarial examples for the OpenAI CLIP in its zero-shot classification regime and their semantic generalization | Stanislav Fort</a></p>
<ul>
<li>it genuinely believes that it's seen a frog or a toad.</li>
</ul></div></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/perception/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-c28e3682d3108d6de117.js"],"app":["/app-019f857f2e3d4b0b87b4.js"],"component---src-pages-404-js":["/component---src-pages-404-js-0e456020558958a6b696.js"],"component---src-pages-index-js":["/component---src-pages-index-js-b73c274f16e777faeea5.js"],"component---src-pages-markdown-remark-frontmatter-slug-js":["/component---src-pages-markdown-remark-frontmatter-slug-js-8a69e30532d0b70ad663.js"]};/*]]>*/</script><script src="/polyfill-c28e3682d3108d6de117.js" nomodule=""></script><script src="/component---src-pages-markdown-remark-frontmatter-slug-js-8a69e30532d0b70ad663.js" async=""></script><script src="/app-019f857f2e3d4b0b87b4.js" async=""></script><script src="/framework-c994c0529d0491ad085b.js" async=""></script><script src="/webpack-runtime-6211f90e7b9220d56700.js" async=""></script></body></html>